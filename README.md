# llm-agent

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A terminal-based environment for interacting with Large Language Models (LLMs), particularly focused on using local context and configurations to create specialized "agents". It utilizes LangChain and Google's Gemini models via the `langchain-google-genai` integration.

## Features

*   **Configurable Agents:** Define different agent personalities, prompts, tools, and context sources via YAML and Markdown files in `config/agents/`.
*   **Context Integration:** Automatically loads context from global (`data/global_context/`) and agent-specific directories (`config/agents/<name>/`, `data/agents/<name>/`).
*   **Interactive Chat (REPL):** Engage in conversations with agents using the `chat` command, which supports command history.
*   **Persistent Memory:** Chat history for each agent is saved automatically (`data/agents/<name>/memory/chat_history.json`) and loaded when you restart a chat session with that agent.
*   **Agent Switching:** Switch between different configured agents within a chat session using the `/agent <name>` command.
*   **Tool Use:** Agents can be configured to use tools (e.g., file system access scoped to specific directories).
*   **Simple Single-Shot Queries:** Use the `ask` command for quick, non-conversational queries.
*   **Configurable Logging:** Control output verbosity with `--log-level` and `--verbose` flags.

## Setup

1.  **Clone the repository:**
    ```bash
    git clone <repository_url>
    cd llm-agent
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv .venv
    source .venv/bin/activate 
    # On Windows use `.venv\Scripts\activate`
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Install the project in editable mode:**
    This step makes the project's modules importable from anywhere within your activated virtual environment, which is necessary for the new packaging structure.
    ```bash
    pip install -e .
    ```

5.  **Configure Environment Variables:**
    *   Create a `.env` file in the project root directory.
    *   Add your Google API key:
        ```dotenv
        GOOGLE_API_KEY="YOUR_API_KEY_HERE"
        ```
    *   You can obtain a key from [Google AI Studio](https://aistudio.google.com/app/apikey).

6.  **(Optional) Configure Settings:**
    *   Review and modify `config/settings.yaml` to change default model names, directory paths, etc.

## Usage

The primary entry point is the `src.cli.main` module.

### Interactive Chat (`chat`)

This is the main way to interact with agents conversationally.

```bash
python -m src.cli.main chat [OPTIONS]
```

**Options:**
*   `--agent <name>` or `-a <name>`: Specify the agent to start the chat with (defaults to `assistant` if not provided).
*   `--log-level <level>`: Set logging level (`debug`, `info`, `warning`, `error`, `critical`). Default is `error`.
*   `--verbose` or `-v`: Enable verbose logging (sets level to `debug`, overrides `--log-level`).

**Example:**
```bash
python -m src.cli.main chat -a test_agent --verbose 
```

**In-Chat Commands:**
*   `/exit`: Quit the chat session. Chat history will be saved.
*   `/agent <name>`: Switch to a different configured agent. The history of the previous agent will be saved before switching.

### Single Question (`ask`)

For non-conversational queries where you provide context via an agent configuration.

```bash
python -m src.cli.main ask <QUERY> [OPTIONS]
```

**Arguments:**
*   `<QUERY>`: The question you want to ask the LLM (required).

**Options:**
*   `--agent <name>` or `-a <name>`: Specify the agent whose context should be loaded and provided to the LLM.
*   `--log-level <level>`: Set logging level.
*   `--verbose` or `-v`: Enable verbose logging.

**Example:**
```bash
python -m src.cli.main ask "What is the secret codeword mentioned in your context?" -a test_agent
```

## Agent Configuration

Agents are defined by creating a subdirectory under `config/agents/`.

*   **`config/agents/<agent_name>/`**: Contains configuration and static context files for an agent.
    *   `agent_meta.yaml`: Defines agent parameters (description, tools, model settings, system prompt file).
    *   `system_prompt.md`: The main instruction prompt for the agent.
    *   Other `.md` or `.yaml` files: Additional static context loaded automatically.
*   **`data/agents/<agent_name>/`**: Contains dynamic data generated by or for the agent.
    *   `agent_data_context.md`: A specific file automatically loaded into the agent's context.
    *   `memory/chat_history.json`: Saved conversation history (created automatically).
    *   Other files/directories created by agent tools (e.g., via `file_management` tool).
*   **`data/global_context/`**: Files here are loaded as context for *all* agents.

See the `config/agents/test_agent/` directory for an example configuration.

## Development

*   **Structure:** Follows standard Python project layout (`src/`, `tests/`).
*   **Dependencies:** Managed in `requirements.txt`.
*   **Testing:** Uses `pytest`. Run tests with `pytest` from the project root.
*   **Contribution:** Please follow standard practices (fork, feature branch, pull request).

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
